# -*- coding: utf-8 -*-
"""9321-assn3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ArF-ftO2evUeE_nqHMqaOXAU1NAofqEt

# preprocessing

dev env colab
## Load csv file from Gdrive
"""

"""# Start"""

import pandas as pd
import numpy as np
import requests
import json
import sys

from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import MinMaxScaler

from sklearn.tree import DecisionTreeRegressor
from sklearn.svm import SVR
from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import AdaBoostRegressor
from sklearn.ensemble import GradientBoostingRegressor

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score

from math import sqrt
import matplotlib.pyplot as plt

# ref: https://stackoverflow.com/questions/20625582/how-to-deal-with-settingwithcopywarning-in-pandas
pd.options.mode.chained_assignment = None  # default='warn'


# get data from args
if len(sys.argv)!=3:
    sys.exit("Input args not valid, please pass path1 path2 to this file.")


TRAIN_PATH = sys.argv[1]
VALID_PATH = sys.argv[2]
Z_ID = 'z5141401'
DECIMAL_LEN = 6

try:
    train_df=pd.read_csv(TRAIN_PATH)
    validation_df=pd.read_csv(VALID_PATH)
except:
    sys.exit("Invalid path or not a csv file, please check your input.")

train_df

"""## Processing data


|Column|Value  |
|--|--|
|Budget|keep value, not convert|
|Genres|convert to number of genres|
|Homepage|convert to boolean (has a homepage or not)|
|original_language|keep???|
|release_date|convert to year|


[release_year_rita.png](https://i.loli.net/2020/04/16/Ul1LeRQtr6PDM3d.png)

[release_year_me](https://pic.luoxufeiyan.com/uploads/20200416145052.png)
"""

# Only keep certain columns as training set

# keep_col = ['budget', 'homepage', 'original_language', 'release_date']
# conv_num_list = ['cast', 'crew', 'genres', 'keywords', 'production_companies', 'production_countries', 'spoken_languages']
keep_col = ['budget', 'homepage', 'release_date']
conv_num_list = ['genres', 'spoken_languages']
Y_label = 'revenue'

# convert-to num
def conv_to_num(dataset, modify_col):
    for i in range(len(dataset[modify_col])):
        curr_str = dataset[modify_col][i] 
        curr_len = len(json.loads(curr_str))
        dataset[modify_col][i] = curr_len
    return dataset

# preprocessing-homepage
def proc_homepage(dataset):
    modify_col = 'homepage'
    for i in range(len(dataset[modify_col])):
        curr_str = dataset[modify_col][i] 
        # convert to Ture if movie has a homepage
        curr_len = (type(curr_str) is str)
        dataset[modify_col][i] = curr_len
    return dataset

# preprocessing-release_date
def proc_rls_date(dataset):
    modify_col = 'release_date'
    for i in range(len(dataset[modify_col])):
        curr_str = dataset[modify_col][i] 
        # convert to year only
        curr_len = int(curr_str[:4])
        dataset[modify_col][i] = curr_len
    return dataset

# original_language
def proc_orig_lang(dataset):
    all_lang = list(set(dataset['original_language'].values))
    le = LabelEncoder()
    le.fit(all_lang)
    dataset['original_language'] = le.transform(dataset['original_language'])
    return dataset

# budget
def proc_budget(dataset):
    modify_col = 'budget'
    #norm certain cols
    y_df = dataset[modify_col]
    y_norm = (y_df - y_df.mean()) / (y_df.max() - y_df.min())
    dataset[modify_col] = y_norm
    return dataset

## TEst only

# proc_dataset = train_df[keep_col]
# str1 = proc_dataset['spoken_languages'][206]
# len(json.loads(str1))

def proc_data(dataset):
    # add Y label
    selected_col = keep_col + conv_num_list
    selected_col.append(Y_label)
    proc_dataset = dataset[selected_col]
    # proc_dataset = dataset[keep_col]

    # do preprocessing
    #convert to num
    for i in conv_num_list:
        try:
            proc_dataset = conv_to_num(proc_dataset, i)
        except:
            print(i)

    # other processing
    proc_dataset = proc_budget(proc_dataset)
    proc_dataset = proc_homepage(proc_dataset)
    proc_dataset = proc_rls_date(proc_dataset)

    #norm certain cols
    y_df = dataset[Y_label]
    y_norm = (y_df - y_df.mean()) / (y_df.max() - y_df.min())
    proc_dataset[Y_label] = y_norm
    
    return proc_dataset

train_set = proc_data(train_df)
vali_set = proc_data(validation_df)
train_set

"""# Fit models

* https://www.pluralsight.com/guides/non-linear-regression-trees-scikit-learn

* https://github.com/wangye707/PY_DELL/blob/b066ae4bb40273b24d698d66450e4207e3eb6808/git_book-master/chapters/Decision_Tree/decisiontree_regressor.py
"""

keep_col = keep_col + conv_num_list

X_train = train_set[keep_col]
Y_train = train_set[Y_label]

X_valid = vali_set[keep_col]
Y_valid = vali_set[Y_label]



"""### decision tree"""

def dTree(X_train, Y_train):
    model_dtree = DecisionTreeRegressor()
    # dtree = DecisionTreeRegressor()
    model_dtree.fit(X_train, Y_train)

    return model_dtree

"""### random forest"""

def randomForest(X_train, Y_train):
    #RF model
    model_rf = RandomForestRegressor(n_estimators=500, oob_score=True, random_state=100)
    # model_rf = RandomForestRegressor(n_estimators=500)
    model_rf.fit(X_train, Y_train) 

    return model_rf

"""### Adaboost"""

def adaBoost(X_train, Y_train):
    model_ab = AdaBoostRegressor(n_estimators=500)
    model_ab.fit(X_train, Y_train)

    return model_ab

"""### GBRT"""

def gbrt(X_train, Y_train):
    model_gbrt = GradientBoostingRegressor(n_estimators=500)
    model_gbrt.fit(X_train, Y_train)

    return model_gbrt

"""# Evaluate"""

model_gbrt = gbrt(X_train, Y_train)

model = model_gbrt

# For validation set
# print summary
lst = [Z_ID]
summary_1_filename = Z_ID + '.PART1.summary.csv'
Y_valid_pred = model.predict(X_valid)
lst.append(round(mean_squared_error(Y_valid,Y_valid_pred), DECIMAL_LEN)) 
lst.append(round(model.score(X_valid,Y_valid), DECIMAL_LEN))
    
summary_1 = pd.DataFrame([lst], columns =['zid','MSR','correlation']) 
summary_1.to_csv(summary_1_filename, index=False)



"""# P2

https://blog.csdn.net/u010900574/article/details/52669072
"""

# Only keep certain columns as training set

# keep_col = ['budget', 'homepage', 'original_language', 'release_date']
# conv_num_list = ['cast', 'crew', 'genres', 'keywords', 'production_companies', 'production_countries', 'spoken_languages']
keep_col = ['budget', 'homepage', 'release_date']
conv_num_list = ['genres', 'spoken_languages']
Y_label = 'rating'

def proc_data(dataset):
    # add Y label
    selected_col = keep_col + conv_num_list
    selected_col.append(Y_label)
    proc_dataset = dataset[selected_col]
    # proc_dataset = dataset[keep_col]

    # do preprocessing
    #convert to num
    for i in conv_num_list:
        try:
            proc_dataset = conv_to_num(proc_dataset, i)
        except:
            print(i)

    # other processing
    proc_dataset = proc_budget(proc_dataset)
    proc_dataset = proc_homepage(proc_dataset)
    proc_dataset = proc_rls_date(proc_dataset)

    # #norm certain cols
    # y_df = dataset[Y_label]
    # y_norm = (y_df - y_df.mean()) / (y_df.max() - y_df.min())
    # proc_dataset[Y_label] = y_norm
    
    return proc_dataset

train_set = proc_data(train_df)
vali_set = proc_data(validation_df)
train_set

keep_col = keep_col + conv_num_list

X_train = train_set[keep_col]
Y_train = train_set[Y_label]

X_valid = vali_set[keep_col]
Y_valid = vali_set[Y_label]

from sklearn import tree, svm, naive_bayes,neighbors
from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, RandomForestClassifier, GradientBoostingClassifier



clfs = {'svm': svm.SVC(),\
        'decision_tree':tree.DecisionTreeClassifier(),
        'naive_gaussian': naive_bayes.GaussianNB(), \
        # 'naive_mul':naive_bayes.MultinomialNB(),\
        'K_neighbor' : neighbors.KNeighborsClassifier(),\
        'bagging_knn' : BaggingClassifier(neighbors.KNeighborsClassifier(), max_samples=0.5,max_features=0.5), \
        'bagging_tree': BaggingClassifier(tree.DecisionTreeClassifier(), max_samples=0.5,max_features=0.5),
        'random_forest' : RandomForestClassifier(n_estimators=50),\
        'adaboost':AdaBoostClassifier(n_estimators=50),\
        'gradient_boost' : GradientBoostingClassifier(n_estimators=50, learning_rate=1.0,max_depth=1, random_state=10)
        }

def try_different_method(clf):
    clf.fit(X_train,Y_train)
    score = clf.score(X_valid,Y_valid)
    print('the score is :', score)

for clf_key in clfs.keys():
    print('the classifier is :',clf_key)
    clf = clfs[clf_key]
    try_different_method(clf)

